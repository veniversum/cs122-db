CS122 Assignment 2 - SQL Planning and Joins - Design Document
=============================================================

A:  Logistics
-------------

A1.  List your team name and the people who worked on this assignment.

     <team name>'); DROP TABLE Teams;--

     Qingzhuo Aw Young <qingzhuo@caltech.edu>
     Timur Kuzhagaliyev <timbokz@caltech.edu>

A2.  Specify the repository URL, tag name and commit-hash of the Git version
     you are submitting for your assignment.  (You can list the commit hashes
     of your repository tags with this command:  git show-ref --tags)

     Repository URL:  git@github.com:veniversum/cs122-db.git
     Tag name:        <tag>
     Commit hash:     <hash>

A3.  Specify any late tokens you are applying to this assignment, or
     "none" if no late tokens.

     None

A4.  Briefly describe what parts of the assignment each teammate focused on.

     Qingzhuo: project, joins, rename, expression processor, grouping & aggregate, limit offset
     Timur: tests, fixing minor bugs, subqueries in WHERE/SELECT clauses

B:  Simple Planner
------------------

B1.  Without going into the details of how you handle grouping and
     aggregation or joins, list the general sequence of steps that your
     planner's makePlan() method follows to translate a SQL query into
     an execution plan.

     1. Replace non simple functions in select values & having expressions
        with column values
     2. Recursively process FROM clause (joins, renames, etc)
     3. Filter on where clause if present
     4. Process grouping & aggregates if present, actually evaluating
        function calls into columns in 1.
     5. Filter on having clause if present
     6. Project onto actual output schema if non trivial
     7. Sort output if necessary
     8. Apply limit and offsets if necessary
     9. Recursively prepare() plan nodes
     10. Return root plan node

B2.  Does your planner try to simplify plans in specific circumstances,
     e.g. when a "trivial project" is used (i.e. "SELECT * FROM ...") in
     your planner?  Briefly enumerate all simplifications and optimizations
     your planner employs.

     Yes. As mentioned in B1, processing steps are only performed if needed.
     We *mostly* don't add nodes which perform no-ops.

B3.  Describe how you generate the execution-plan fragment for the query's
     FromClause.  Make sure to touch on what you do in the three cases your
     planner is expected to handle - tables, subqueries in the FROM clause,
     and joins.

     The plan fragment for the FromClause is built by the method
     SimplePlanner#deconstructFrom.

     * Recursively deconstructs the fromClause into it's plan nodes by preorder
     * traversal of the fromClause tree.

     Tables : generate FileScanNode
     Joins : generate NestedLoopJoinNode of recursively deconstructed L/R childs
     Subqueries : recursion call to makePlan with fromClause.getSelectClause().
     Note; correlated subqueries are not supported in FROM clause yet.

B4.  Describe how you implemented support for grouping and aggregation.
     Be sure to note any variations from the approach outlined in class,
     if there are any.

     Refer to B1 for step labels.

     In (1.), we replace aggregate function calls with column values, and
     keep track of the mapping between replacement strings and function
     calls. The functions will be evaluated later in (4.) if necessary.

     We filter on the WHERE clause (3.) before the grouping and aggregate
     steps in (4.) because we don't want filtered results to be in the
     aggregates, but filter on the HAVING clause (5.) after processing the
     aggregates because expressions within it might be have the group or
     aggregate as arguments.

C:  Nested-Loop Join
--------------------

C1.  The join algorithm stated in class is really only suitable for
     materialized evaluation, where the entire result is generated by the
     algorithm.  It is completely unsuitable for pipelined evaluation,
     where results are generated row by row.

     Summarize how your implementation works for inner joins, using
     pseudocode to show how rows are considered and returned as the
     algorithm executes, and what state must be saved so that the
     operation can resume at the appropriate place when the next row
     must be returned.

     This is the pseudocode showing the _logic_ of the joins.

     for l_tuple in l_child:
         for r_tuple in r_child:
             if can_join(l_tuple, r_tuple):
                 join(l_tuple, r_tuple)

     However due to the interface exposed by NestedLoopJoinNode,
     we have to keep the state of the loop as instance variables,
     by manually iterating through each child, and resetting the
     iterator for the inner child when we reach the end.

     Our join terminates when the outer child runs out of tuples.

C2.  What tweaks did you need to introduce into the implementation for
     left outer joins?  Keep your answer brief, but please also be specific.

     In prepare(), we convert any right outer joins into left outer joins
     by simply swapping the left and right childs, and the schema.
     Note that at this point both l/r joins will be LEFT_JOINs.

     Additionally, we keep track of whether the current tuple in the
     outer(left) child has already been joined.

     We can simply add this condition to canJoinTuples logic.
     if (rightTuple == null && !joined)
            return joinType == JoinType.LEFT_OUTER;

     ThetaJoinNode#joinTuples is also modified to accept null tuples,
     which will then create a tuple of nulls with the according schema.

C3.  Enumerate your nested-loop join test cases, following this form:

     * TestSimpleJoins.testSimpleJoinsNeitherEmpty
       Checks that join is performed correctly when both tables are
       non-empty

     * TestSimpleJoins.testSimpleJoinLeftEmpty
       Checks that all joins are performed correctly when left table is
       empty and right table is non-empty

     * TestSimpleJoins.testSimpleJoinRightEmpty
       Checks that all joins are performed correctly when left table is
       non-empty and right table is empty

     * TestSimpleJoins.testSimpleJoinBothEmpty
       Checks that all joins are performed correctly when both tables
       are empty

     * TestSimpleJoins.testSimpleJoinMatchMultipleInRight
       Checks that all joins are performed correctly when both tables
       are non-empty and some of the rows from the left table
       match multiple rows in the right table

     * TestSimpleJoins.testSimpleJoinMatchMultipleInLeft
       Checks that all joins are performed correctly when both tables
       are non-empty and some of the rows from the right table
       match multiple rows in the left table

D:  Extra Credit [OPTIONAL]
---------------------------

If you implemented any extra-credit tasks for this assignment, describe
them here.  The description should be like this, with stuff in "<>" replaced.
(The value i starts at 1 and increments...)

D<1>:  Limit & offset clauses

     Implement LIMIT and OFFSET in LimitOffsetNode. Our implementation
     supports the OFFSET clause without requiring a LIMIT.

     Tests are in class TestLimitOffset
     testLimitOffsetTablesNotEmpty : standard test to ensure table is created properly
     testOffsetOnly : tests OFFSET clause in isolation, covers edge cases.
     testLimitOnly : tests LIMIT clause in isolation, covers edge cases.
     testLimitAndOffset : tests OFFSET and LIMIT clause together.

D<2>:  Passing the tests for scalar subqueries in SELECT and other subqueries
       in WHERE clauses

E:  Feedback [OPTIONAL]
-----------------------

WE NEED YOUR FEEDBACK!  Thoughtful and constructive input will help us to
improve future versions of the course.  These questions are OPTIONAL, and
they obviously won't affect your grade in any way (including if you hate
everything about the assignment and databases in general, or Donnie and/or
the TAs in particular).  Feel free to answer as many or as few of them as
you wish.

E1.  How many hours total did your team spend on this assignment?
     (That is, the sum of each teammate's time spent on the assignment.)

     20

E2.  What parts of the assignment were most time-consuming?  Why?

     Fixing various bugs in nanodb. Deciphering design and program flow.
     How ExpressionProcessor works and where it fits in the pipeline is
     particularly non-intuitive.

E3.  Did you find any parts of the assignment particularly instructive?
     Correspondingly, did any parts feel like unnecessary busy-work?

E4.  Did you particularly enjoy any parts of the assignment?  Were there
     any parts that you particularly disliked?

E5.  Do you have any suggestions for how future versions of the
     assignment can be improved?
